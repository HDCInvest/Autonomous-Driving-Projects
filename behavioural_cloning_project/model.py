import csv
import cv2
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Flatten,Dense,Lambda,BatchNormalization,Activation,Cropping2D,Dropout
from keras.layers.convolutional import Convolution2D
from keras.layers.pooling import MaxPooling2D

#Generator function to yield data
def generator(samples,batch_size=32):
    '''
    This function is for feeding data in batches during training,so that less data is stored in memory
    '''
    num_samples = len(samples)
    while 1:
        samples = sklearn.utils.shuffle(samples)
        for offset in range(0,num_samples,batch_size):
            batch_samples = samples[offset:offset+batch_size]

            #Place holders for image and steering angle
            images = []
            measurements = []
            #Following code segment is for data augmentation. 
            # All 3 images are used ( left,center and right camera images ) and used correction of 0.25
            # Additional data is generated by flipping the image and measurement for generalization.
            # Image pre processing is not done here, but taken care in keras during model building
            for line in batch_samples:
                #center image
                source_path = line[0]
                filename = source_path.split('/')[-1]
                current_path = '../data/IMG/' + filename
                image = cv2.imread(current_path)
                center_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                #left image
                source_path = line[1]
                filename = source_path.split('/')[-1]
                current_path = '../data/IMG/' + filename
                image = cv2.imread(current_path)
                left_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                #right image
                source_path = line[2]
                filename = source_path.split('/')[-1]
                current_path = '../data/IMG/' + filename
                image = cv2.imread(current_path)
                right_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                #Steering measurements
                correction = .25
                measurement = float(line[3])
                left_measurement = measurement + correction
                right_measurement = measurement - correction
                images.extend([center_image,left_image,right_image])
                measurements.extend([measurement,left_measurement,right_measurement])

            #Place holder for final augmented images
            augmented_images,augmented_measurements = [],[]
            for image,measurement in zip(images,measurements):
                augmented_images.append(image)
                augmented_measurements.append(measurement)
                augmented_images.append(cv2.flip(image,1))
                augmented_measurements.append(measurement*-1.0)
            
            #Convert the list to numpy array as keras need input as arrays
            X_train = np.array(augmented_images)
            y_train = np.array(augmented_measurements)
            yield sklearn.utils.shuffle(X_train, y_train)
            
# Define the model architecture  and return it
def lenet_model(drop_out=0.2):
    '''
    Takes LeNet architecture as base and modifies it to suit the current problem.
    Image preprocessing steps added : first the image is normalized.
    And then image size is cropped by removing some upper and lower portion of the images. This helped in training time and also rmeoved noisy data
    First convolutional layer has output size of 12 instead of 6 used in standrad LeNet architecture
    Batch normalization is done between every linear and non linear layer and this helped a lot
    Dropout has been added to biggest fully connected layer to help generalize the model better
    Activation function relu is used after every block of conv + batch norm + max pool layer and after fully connected layers .
    Input : Image of size 160,320,3
    Output : Returns the model structure
    '''
    # Model Architecture
    model = Sequential()
    #Normalize the data
    model.add(Lambda(lambda x : x/255.0 - .5 , input_shape=(160,320,3)))
    #Resize the images by cropping unwanted portion of the images
    model.add(Cropping2D(cropping=((70,25),(0,0))))
    # First conv + MaxPooling layer with relu activation and batch normalization
    model.add(Convolution2D(12,5,5,activation='relu',use_bias=False))
    model.add(BatchNormalization())
    model.add(Activation("relu"))
    model.add(MaxPooling2D())
    # Second conv + MaxPooling layer with relu activation and batch normalization
    model.add(Convolution2D(16,5,5,activation='relu',use_bias=False))
    model.add(BatchNormalization())
    model.add(Activation("relu"))
    model.add(MaxPooling2D())
    #Flattern the output to feed to fulling connected network
    model.add(Flatten())
    # First fulling connected layer with batch normalization, relu activation and dropout
    model.add(Dense(120, use_bias=False))
    model.add(BatchNormalization())
    model.add(Activation("relu"))
    model.add(Dropout(drop_out))
    # Second fulling connected layer with batch normalization and relu activation
    model.add(Dense(84, use_bias=False))
    model.add(BatchNormalization())
    model.add(Activation("relu"))
    #Final output layer
    model.add(Dense(1))
    return model

### Following section of the code contains the entire pipe line of code.
# Read Data -> Split Data -> Define Model -> Compile Model -> Train Model using generators & validate using 20% data
# Generator function handles data augmentation steps in batches and this is done during training, so that memory usage is limited and we can handle large volume of data.

#Read the data
print(' Reading driving_log and image files')
lines = []  # To store the csv data
with open('../data/driving_log.csv') as csvfile:
    reader = csv.reader(csvfile)
    count = 0
    for line in reader:
        if count > 0 :           #Skip the first row of the csv file
            lines.append(line)
        count = count + 1
        
# Split train data into train and validate sets ( 20% )
# 20% data is used as validation set and the final testing is done on the track 1.
X = lines
y  = [1 for i in lines]   #Just a dummy label
train_samples,validation_samples,y_train,y_validate = train_test_split(X,y, test_size=0.2)


# compile and train the model using the generator function
BATCH_SIZE = 64    # Used by generator functions
train_generator = generator(train_samples, batch_size=BATCH_SIZE)
validation_generator = generator(validation_samples, batch_size=BATCH_SIZE)

# Using adam optimizer and mse as loss function
# EPOCH of 9 was good enough and larger epochs lead to overfitting.
# When used without generator epoch of 5 was good enough.
# Tried with both batch size of 32 and 64. 64 worked better for the existing combinations.

model = lenet_model()    # returns a model structure
model.compile(loss='mse',optimizer='adam')    # Use mse as loss function and adam optimizer
model.fit_generator(train_generator, 
                    steps_per_epoch = len(train_samples)//BATCH_SIZE, 
                    validation_data=validation_generator,
                    validation_steps=len(validation_samples)//BATCH_SIZE, 
                    nb_epoch=9)

#Save the model file
model.save('model.h5')
 
